{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datasets\n",
    "movies_path = r\"C:\\Users\\paula\\OneDrive\\Curso\\Henry\\Proyecto Individual\\Movies\\movies_dataset.csv\"\n",
    "credits_path = r\"C:\\Users\\paula\\OneDrive\\Curso\\Henry\\Proyecto Individual\\Movies\\credits.csv\"\n",
    "\n",
    "movies = pd.read_csv(movies_path, low_memory=False)\n",
    "credits = pd.read_csv(credits_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que 'revenue' y 'budget' son numéricos y reemplazar nulos por 0\n",
    "movies['revenue'] = pd.to_numeric(movies['revenue'], errors='coerce').fillna(0)\n",
    "movies['budget'] = pd.to_numeric(movies['budget'], errors='coerce').fillna(0)\n",
    "\n",
    "# Calcular 'return'\n",
    "movies['return'] = np.where(movies['budget'] == 0, 0, movies['revenue'] / movies['budget'])\n",
    "\n",
    "# Reemplazar divisiones por cero o valores nulos directamente\n",
    "movies['return'] = movies['return'].replace([np.inf, np.nan], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir release_date al formato datetime y manejar errores\n",
    "movies['release_date'] = pd.to_datetime(movies['release_date'], errors='coerce')\n",
    "\n",
    "# Crear la columna release_year extrayendo el año\n",
    "movies['release_year'] = movies['release_date'].dt.year\n",
    "\n",
    "# Crear la columna release_month extrayendo el mes\n",
    "movies['release_month'] = movies['release_date'].dt.month\n",
    "\n",
    "# Crear la columna release_dow extrayendo el dia de la semana\n",
    "movies['release_dow'] = movies['release_date'].dt.day_of_week\n",
    "\n",
    "# Eliminar aquellos registros que quedaron nulos\n",
    "movies = movies[movies['release_year'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.drop(columns=['video', 'imdb_id', 'adult', 'original_title', 'poster_path', 'homepage', 'spoken_languages', 'production_countries', 'belongs_to_collection', 'production_companies', 'original_language','tagline', 'genres', 'overview', 'runtime', 'status'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar duplicados de \"title\" conservando el registro con mayor popularidad\n",
    "movies = movies.sort_values(by='popularity', ascending=False)  # Ordenar por popularidad\n",
    "movies = movies.drop_duplicates(subset=['title'], keep='first')  # Eliminar duplicados conservando el primero (el de mayor popularidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna `crew` en listas de diccionarios\n",
    "credits['crew'] = credits['crew'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Extraer el nombre de los directores\n",
    "credits['director_name'] = credits['crew'].apply(\n",
    "    lambda x: next((person['name'] for person in x if person.get('job') == 'Director'), None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna `cast` en listas de diccionarios\n",
    "credits['cast'] = credits['cast'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Extraer los nombres de todos los actores en una lista\n",
    "credits['actors'] = credits['cast'].apply(\n",
    "    lambda x: [actor['name'] for actor in x] if isinstance(x, list) else []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame reducido\n",
    "credits = credits[['id', 'director_name', 'actors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de movies_dataset: (42196, 12)\n",
      "Dimensiones de credits: (45476, 3)\n"
     ]
    }
   ],
   "source": [
    "# Tamaño de los datasets\n",
    "print(\"Dimensiones de movies_dataset:\", movies.shape)\n",
    "print(\"Dimensiones de credits:\", credits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas de movies_dataset:\n",
      "['budget', 'id', 'popularity', 'release_date', 'revenue', 'title', 'vote_average', 'vote_count', 'return', 'release_year', 'release_month', 'release_dow']\n",
      "\n",
      "Columnas de credits:\n",
      "['id', 'director_name', 'actors']\n"
     ]
    }
   ],
   "source": [
    "# Nombres de las columnas\n",
    "print(\"Columnas de movies_dataset:\")\n",
    "print(movies.columns.tolist())\n",
    "print(\"\\nColumnas de credits:\")\n",
    "print(credits.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos de movies_dataset:\n",
      "budget                  float64\n",
      "id                       object\n",
      "popularity               object\n",
      "release_date     datetime64[ns]\n",
      "revenue                 float64\n",
      "title                    object\n",
      "vote_average            float64\n",
      "vote_count              float64\n",
      "return                  float64\n",
      "release_year            float64\n",
      "release_month           float64\n",
      "release_dow             float64\n",
      "dtype: object\n",
      "\n",
      "Tipos de datos de credits:\n",
      "id                int64\n",
      "director_name    object\n",
      "actors           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Tipos de datos\n",
    "print(\"Tipos de datos de movies_dataset:\")\n",
    "print(movies.dtypes)\n",
    "print(\"\\nTipos de datos de credits:\")\n",
    "print(credits.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en movies_dataset:\n",
      "budget           0\n",
      "id               0\n",
      "popularity       0\n",
      "release_date     0\n",
      "revenue          0\n",
      "title            0\n",
      "vote_average     0\n",
      "vote_count       0\n",
      "return           0\n",
      "release_year     0\n",
      "release_month    0\n",
      "release_dow      0\n",
      "dtype: int64\n",
      "\n",
      "Valores nulos en credits:\n",
      "id                 0\n",
      "director_name    887\n",
      "actors             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Valores nulos\n",
    "print(\"Valores nulos en movies_dataset:\")\n",
    "print(movies.isnull().sum())\n",
    "print(\"\\nValores nulos en credits:\")\n",
    "print(credits.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros duplicados en movies_dataset: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Duplicados\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegistros duplicados en movies_dataset:\u001b[39m\u001b[38;5;124m\"\u001b[39m, movies\u001b[38;5;241m.\u001b[39mduplicated()\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegistros duplicados en credits:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mcredits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduplicated\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[1;32mc:\\Users\\paula\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:6958\u001b[0m, in \u001b[0;36mDataFrame.duplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6957\u001b[0m     vals \u001b[38;5;241m=\u001b[39m (col\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m name, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m subset)\n\u001b[1;32m-> 6958\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   6960\u001b[0m     ids \u001b[38;5;241m=\u001b[39m get_group_index(labels, \u001b[38;5;28mtuple\u001b[39m(shape), sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   6961\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(duplicated(ids, keep), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\paula\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:6926\u001b[0m, in \u001b[0;36mDataFrame.duplicated.<locals>.f\u001b[1;34m(vals)\u001b[0m\n\u001b[0;32m   6925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(vals) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m-> 6926\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;28mlen\u001b[39m(shape)\n",
      "File \u001b[1;32mc:\\Users\\paula\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[0;32m    803\u001b[0m         uniques,\n\u001b[0;32m    804\u001b[0m         codes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    808\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\paula\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[0;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7281\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7195\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Duplicados\n",
    "print(\"Registros duplicados en movies_dataset:\", movies.duplicated().sum())\n",
    "print(\"Registros duplicados en credits:\", credits.duplicated().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
